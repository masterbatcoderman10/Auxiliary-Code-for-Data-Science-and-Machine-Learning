{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TF_IDF:\n",
    "\n",
    "    def __init__(self, text_data):\n",
    "        self.text_data = text_data\n",
    "        self.words_cleaned = []\n",
    "        self.word_dict_index = {}\n",
    "        self.word_count_dict = {}\n",
    "        self.IDF = {}        \n",
    "        self.pattern = r\"[^?.,!:; ]+\"\n",
    "        self.unique_words = self.clean()\n",
    "        \n",
    "        for i, word in enumerate(self.unique_words):\n",
    "            self.word_dict_index[word] = i\n",
    "            self.word_count_dict[word] = 0 \n",
    "            self.IDF[word] = 0\n",
    "            \n",
    "        self.total_word_count()\n",
    "        self.doc_matrix = np.zeros((len(self.text_data), len(self.unique_words)))\n",
    "        self.tf_idf = np.zeros((len(self.text_data), len(self.unique_words)))\n",
    "\n",
    "    \n",
    "    def clean(self):\n",
    "        all_text = \" \".join(self.text_data)\n",
    "        words = re.findall(self.pattern, all_text)\n",
    "        self.words_cleaned = [word.lower() for word in words]\n",
    "        return sorted(set(self.words_cleaned))\n",
    "    \n",
    "    def total_word_count(self):\n",
    "        for word in self.words_cleaned:\n",
    "            self.word_count_dict[word] += 1\n",
    "        \n",
    "        #print(self.word_count_dict)\n",
    "\n",
    "    \n",
    "    def tf(self):\n",
    "        for i,text_doc in enumerate(self.text_data):\n",
    "            text_words = re.findall(self.pattern, text_doc.lower())\n",
    "            for word in text_words:\n",
    "                w = self.word_dict_index[word]\n",
    "                self.doc_matrix[i][w] += 1\n",
    "    \n",
    "    def idf(self):\n",
    "\n",
    "        for word in self.words_cleaned:\n",
    "            ttf = self.word_count_dict[word]\n",
    "            D = len(self.text_data)\n",
    "            idf = np.log((D / ttf))\n",
    "            self.IDF[word] = idf\n",
    "    \n",
    "    def create_tf_idf(self):\n",
    "        for i,text_doc in enumerate(self.text_data):\n",
    "            text_words = re.findall(self.pattern, text_doc.lower())\n",
    "            for word in text_words:\n",
    "                w = self.word_dict_index[word]\n",
    "                self.tf_idf[i][w] = self.IDF[word]\n",
    "    \n",
    "    def prepare(self):\n",
    "\n",
    "        self.tf()\n",
    "        self.idf()\n",
    "        self.create_tf_idf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSA:\n",
    "    \n",
    "    def __init__(self, doc_matrix, weight):\n",
    "        self.weight = weight\n",
    "        self.doc_matrix = doc_matrix\n",
    "        U, S, V_t = np.linalg.svd(doc_matrix)\n",
    "        self.U = U\n",
    "        self.V = V_t.T\n",
    "        self.S = self.get_eigvals()\n",
    "        \n",
    "        self.cutoff()\n",
    "        \n",
    "    def get_eigvals(self):\n",
    "        XTX = np.matmul(self.doc_matrix.T, self.doc_matrix)\n",
    "        l, e = np.linalg.eig(XTX)\n",
    "        S = np.array(sorted(l, reverse=True))\n",
    "        return S\n",
    "    \n",
    "    def cutoff(self):\n",
    "        self.S = self.S[self.S > self.weight]\n",
    "        rank = len(self.S)\n",
    "        self.U = self.U[:, :rank]\n",
    "        self.V = self.V[:, :rank]\n",
    "        \n",
    "    \n",
    "    def topic_affinity(self, word_list):\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def cosine_similarity(self, vec_1, vec_2):\n",
    "        vec_1_norm = np.linalg.norm(vec_1)\n",
    "        vec_2_norm = np.linalg.norm(vec_2)\n",
    "        return np.dot(vec_1, vec_2) / (vec_1_norm * vec_2_norm)\n",
    "        \n",
    "    def project(self):\n",
    "        \n",
    "        doc_topic = np.matmul(self.doc_matrix, self.V)\n",
    "        return doc_topic\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Roses are lovely. Nobody hates roses.\",\n",
    "    \"Gun violence has reached an epidemic proportion in America.\",\n",
    "    \"The issue of gun violence is really over-hyped. One can find many instances of violence where no guns were involved.\",\n",
    "    \"Guns are for violence prone people. Violence begets guns.\",\n",
    "    \" I like guns but I hate violence. I have never been involved in violence. But I own many guns. Gun violence is incomprehensible to me. I do believe gun owners are the most anti violence people on the planet. He who never uses a gun will be prone to senseless violence.\",\n",
    "    \"Guns were used in a armed robbery in San Francisco last night.\",\n",
    "    \"Acts of violence usually involve a weapon.\",\n",
    "    \"Weapon related violence is on a surge, with 1 public shooting a day in New York.\",\n",
    "    \"Teen girl kills 7 in violent school shootout, in what is another weapon related crime\",\n",
    "    \"Idaho senator criticizes critics of weapon violence\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TF_IDF(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1,\n",
       " '7': 1,\n",
       " 'a': 5,\n",
       " 'acts': 1,\n",
       " 'america': 1,\n",
       " 'an': 1,\n",
       " 'another': 1,\n",
       " 'anti': 1,\n",
       " 'are': 3,\n",
       " 'armed': 1,\n",
       " 'be': 1,\n",
       " 'been': 1,\n",
       " 'begets': 1,\n",
       " 'believe': 1,\n",
       " 'but': 2,\n",
       " 'can': 1,\n",
       " 'crime': 1,\n",
       " 'criticizes': 1,\n",
       " 'critics': 1,\n",
       " 'day': 1,\n",
       " 'do': 1,\n",
       " 'epidemic': 1,\n",
       " 'find': 1,\n",
       " 'for': 1,\n",
       " 'francisco': 1,\n",
       " 'girl': 1,\n",
       " 'gun': 5,\n",
       " 'guns': 6,\n",
       " 'has': 1,\n",
       " 'hate': 1,\n",
       " 'hates': 1,\n",
       " 'have': 1,\n",
       " 'he': 1,\n",
       " 'i': 5,\n",
       " 'idaho': 1,\n",
       " 'in': 7,\n",
       " 'incomprehensible': 1,\n",
       " 'instances': 1,\n",
       " 'involve': 1,\n",
       " 'involved': 2,\n",
       " 'is': 4,\n",
       " 'issue': 1,\n",
       " 'kills': 1,\n",
       " 'last': 1,\n",
       " 'like': 1,\n",
       " 'lovely': 1,\n",
       " 'many': 2,\n",
       " 'me': 1,\n",
       " 'most': 1,\n",
       " 'never': 2,\n",
       " 'new': 1,\n",
       " 'night': 1,\n",
       " 'no': 1,\n",
       " 'nobody': 1,\n",
       " 'of': 4,\n",
       " 'on': 2,\n",
       " 'one': 1,\n",
       " 'over-hyped': 1,\n",
       " 'own': 1,\n",
       " 'owners': 1,\n",
       " 'people': 2,\n",
       " 'planet': 1,\n",
       " 'prone': 2,\n",
       " 'proportion': 1,\n",
       " 'public': 1,\n",
       " 'reached': 1,\n",
       " 'really': 1,\n",
       " 'related': 2,\n",
       " 'robbery': 1,\n",
       " 'roses': 2,\n",
       " 'san': 1,\n",
       " 'school': 1,\n",
       " 'senator': 1,\n",
       " 'senseless': 1,\n",
       " 'shooting': 1,\n",
       " 'shootout': 1,\n",
       " 'surge': 1,\n",
       " 'teen': 1,\n",
       " 'the': 3,\n",
       " 'to': 2,\n",
       " 'used': 1,\n",
       " 'uses': 1,\n",
       " 'usually': 1,\n",
       " 'violence': 13,\n",
       " 'violent': 1,\n",
       " 'weapon': 4,\n",
       " 'were': 2,\n",
       " 'what': 1,\n",
       " 'where': 1,\n",
       " 'who': 1,\n",
       " 'will': 1,\n",
       " 'with': 1,\n",
       " 'york': 1}"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 93)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = LSA(X, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proj = lsa.project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\"violence\", \"gun\", \"america\", \"roses\"]\n",
    "doc_term_matrix = np.array([[0, 0, 0, 2], [1, 1, 1, 0], [2, 2, 0, 0], [3, 3, 0, 0], [5, 5, 0, 0], [0, 1, 0, 0], [1, 0, 0, 0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cbd400ed05db1546209cf0ce449d447a50b69d60697d23e48a62ee68cf2bbaf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
